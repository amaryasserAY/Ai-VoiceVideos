import os
import json
import google.generativeai as genai
import streamlit as st
from pydantic import BaseModel, Field, ValidationError, field_validator
from typing import List, Optional, Literal
from . import command_cache

# ============================================
# IMPORT LOCAL PARSER
# ============================================
import re

class SmartLocalParser:
    """Parser ŸÖÿ≠ŸÑŸä - ŸäÿπÿßŸÑÿ¨ 70% ŸÖŸÜ ÿßŸÑÿ£ŸàÿßŸÖÿ± ÿ®ÿØŸàŸÜ AI!"""
    
    def __init__(self):
        self.arabic_to_english = str.maketrans('Ÿ†Ÿ°Ÿ¢Ÿ£Ÿ§Ÿ•Ÿ¶ŸßŸ®Ÿ©', '0123456789')
    
    def normalize_arabic_numbers(self, text: str) -> str:
        return text.translate(self.arabic_to_english)
    
    def parse_trim(self, text: str) -> Optional[dict]:
        """ŸÖÿπÿßŸÑÿ¨ÿ© ÿ£ŸàÿßŸÖÿ± ÿßŸÑŸÇÿµ."""
        text = self.normalize_arabic_numbers(text.lower())
        
        # "ŸÇÿµ ŸÖŸÜ X ÿ•ŸÑŸâ Y"
        match = re.search(r'(ŸÖŸÜ|ÿ®ÿØÿßŸäÿ©|from|start).+?(\d+\.?\d*).*(ÿ•ŸÑŸâ|ŸÑ|ÿ≠ÿ™Ÿâ|to|until).+?(\d+\.?\d*)', text)
        if match:
            start = float(match.group(2))
            end = float(match.group(4))
            return {'action': 'trim', 'start': start, 'end': end}
        
        # "ÿ£ŸàŸÑ X ÿ´ŸàÿßŸÜŸä"
        match = re.search(r'(ÿ£ŸàŸÑ|ÿßŸàŸÑ|first).+?(\d+\.?\d*)', text)
        if match:
            duration = float(match.group(2))
            return {'action': 'trim', 'start': 0, 'end': duration}
        
        # "ÿ¢ÿÆÿ± X ÿ´ŸàÿßŸÜŸä"  
        match = re.search(r'(ÿ¢ÿÆÿ±|ÿßÿÆÿ±|last).+?(\d+\.?\d*)', text)
        if match:
            duration = float(match.group(2))
            return {'action': 'trim_last', 'duration': duration}
        
        return None
    
    def parse_speed(self, text: str) -> Optional[dict]:
        text = self.normalize_arabic_numbers(text.lower())
        match = re.search(r'(ÿ≥ÿ±ÿπ|ÿßÿ≥ÿ±ÿπ|speed|fast).+?(\d+\.?\d*)x?|x(\d+\.?\d*)', text)
        if match:
            factor = float(match.group(2) or match.group(3))
            return {'action': 'speed', 'factor': factor}
        return None
    
    def parse_crop(self, text: str) -> Optional[dict]:
        text = text.lower()
        if any(k in text for k in ['9:16', 'ÿ±ŸäŸÑÿ≤', 'reels', 'shorts', 'tiktok']):
            return {'action': 'crop', 'aspect_ratio': '9:16'}
        if any(k in text for k in ['16:9', 'ŸäŸàÿ™ŸäŸàÿ®', 'youtube']):
            return {'action': 'crop', 'aspect_ratio': '16:9'}
        if any(k in text for k in ['1:1', 'ŸÖÿ±ÿ®ÿπ', 'square', 'post', 'instagram']):
            return {'action': 'crop', 'aspect_ratio': '1:1'}
        return None
    
    def parse_rotate(self, text: str) -> Optional[dict]:
        text = text.lower()
        if '90' in text:
            return {'action': 'rotate', 'angle': 90}
        if '180' in text:
            return {'action': 'rotate', 'angle': 180}
        if '270' in text:
            return {'action': 'rotate', 'angle': 270}
        return None
    
    def parse(self, text: str) -> Optional[dict]:
        """ÿßŸÑŸÖÿπÿßŸÑÿ¨ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä."""
        if not text or len(text.strip()) < 3:
            return None
        
        text_normalized = text.lower().strip()
        actions = []
        
        # Mute
        if any(k in text_normalized for k in ['ŸÉÿ™ŸÖ', 'ÿßŸÉÿ™ŸÖ', 'mute', 'ÿ¥ŸäŸÑ ÿßŸÑÿµŸàÿ™', 'ÿ®ÿØŸàŸÜ ÿµŸàÿ™']):
            actions.append({'action': 'mute'})
        
        # Black & White
        if any(k in text_normalized for k in ['ÿßÿ®Ÿäÿ∂', 'ÿ£ÿ®Ÿäÿ∂', 'ÿßÿ≥ŸàÿØ', 'black', 'white', 'bw', 'gray']):
            actions.append({'action': 'black_white'})
        
        # Trim
        trim = self.parse_trim(text)
        if trim:
            actions.append(trim)
        
        # Speed
        speed = self.parse_speed(text)
        if speed:
            actions.append(speed)
        
        # Crop
        crop = self.parse_crop(text)
        if crop:
            actions.append(crop)
        
        # Rotate
        rotate = self.parse_rotate(text)
        if rotate:
            actions.append(rotate)
        
        if actions:
            return {
                'transcription': text,
                'actions': actions,
                'source': 'local_parser üöÄ',
                'from_cache': False,
                'tokens_saved': 100
            }
        
        return None

# Quick Match ŸÑŸÑÿ£ŸàÿßŸÖÿ± ÿßŸÑÿ¥ÿßÿ¶ÿπÿ© ÿ¨ÿØÿßŸã
QUICK_COMMANDS = {
    'ŸÉÿ™ŸÖ ÿßŸÑÿµŸàÿ™': [{'action': 'mute'}],
    'mute': [{'action': 'mute'}],
    'ÿßÿ®Ÿäÿ∂ Ÿàÿßÿ≥ŸàÿØ': [{'action': 'black_white'}],
    'black and white': [{'action': 'black_white'}],
    'ÿ±ŸäŸÑÿ≤': [{'action': 'crop', 'aspect_ratio': '9:16'}],
    'shorts': [{'action': 'crop', 'aspect_ratio': '9:16'}],
    'reels': [{'action': 'crop', 'aspect_ratio': '9:16'}],
    'ÿßŸàŸÑ 5 ÿ´ŸàÿßŸÜŸä': [{'action': 'trim', 'start': 0, 'end': 5}],
    'ÿßŸàŸÑ 10 ÿ´ŸàÿßŸÜŸä': [{'action': 'trim', 'start': 0, 'end': 10}],
    'first 5 seconds': [{'action': 'trim', 'start': 0, 'end': 5}],
}

def quick_match(text: str) -> Optional[dict]:
    """ÿ™ÿ∑ÿßÿ®ŸÇ ŸÅŸàÿ±Ÿä O(1) - ÿ£ÿ≥ÿ±ÿπ ŸÖŸÜ AI ÿ®ŸÄ 1000x!"""
    clean = text.lower().strip().replace('  ', ' ')
    if clean in QUICK_COMMANDS:
        return {
            'transcription': text,
            'actions': QUICK_COMMANDS[clean],
            'source': 'instant_match ‚ö°',
            'from_cache': False,
            'tokens_saved': 150
        }
    return None

# ============================================
# PYDANTIC SCHEMAS
# ============================================
class EditAction(BaseModel):
    action: Literal["trim", "mute", "volume", "speed", "black_white", "music", "rotate", "crop", "subtitle", "trim_last"]
    
    start: Optional[float] = Field(None, ge=0)
    end: Optional[float] = Field(None, ge=0)
    factor: Optional[float] = Field(None, gt=0, le=10)
    volume: Optional[float] = Field(None, ge=0.0, le=2.0)
    level: Optional[float] = Field(None, ge=0.0, le=3.0)
    angle: Optional[int] = Field(None)
    aspect_ratio: Optional[str] = Field(None)
    duration: Optional[float] = Field(None, ge=0)
    
    text: Optional[str] = None
    position: Optional[str] = "bottom"
    fontsize: Optional[int] = 50
    color: Optional[str] = "white"
    bg_color: Optional[str] = "black"

    @field_validator('end')
    def check_end_after_start(cls, v, values):
        if v is not None and values.data.get('start') is not None:
            if v <= values.data['start']:
                raise ValueError('End time must be greater than start time')
        return v

class CommandResponse(BaseModel):
    transcription: str
    actions: List[EditAction]

# ============================================
# AI CONFIGURATION
# ============================================
def configure_ai():
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("API Key not found in .env")
    genai.configure(api_key=api_key)

def _get_system_prompt() -> str:
    """Prompt ŸÖÿÆÿ™ÿµÿ± - ŸÖŸàŸÅÿ± ŸÑŸÑÿ™ŸàŸÉŸäŸÜÿ≤."""
    return """Video editor. Output JSON only.
Actions: trim(start,end), mute(), volume(level), speed(factor), black_white(), rotate(angle), crop(aspect_ratio), music(volume), subtitle(text,start,end).
Example: {"transcription":"cut first 10s","actions":[{"action":"trim","start":0,"end":10}]}"""

# ============================================
# HYBRID INTELLIGENCE SYSTEM
# ============================================
def analyze_command(
    audio_path: str = None, 
    text_prompt: str = None, 
    use_cache: bool = True, 
    cache_threshold: float = 0.85
) -> dict:
    """
    ŸÜÿ∏ÿßŸÖ ÿ∞ŸÉÿßÿ° Ÿáÿ¨ŸäŸÜ:
    1. Quick Match (‚ö° ŸÅŸàÿ±Ÿä)
    2. Local Parser (üöÄ ŸÖÿ≠ŸÑŸä)
    3. Cache (üíæ ÿ∞ÿßŸÉÿ±ÿ©)
    4. AI (ü§ñ ÿ¨ŸäŸÖŸäŸÜŸä) - ÿßŸÑŸÖŸÑÿßÿ∞ ÿßŸÑÿ£ÿÆŸäÿ±!
    """
    
    # ŸÑŸÑÿµŸàÿ™: ÿßÿ∂ÿ∑ÿ±ÿßÿ±ŸäÿßŸã ŸÜÿ≥ÿ™ÿÆÿØŸÖ AI
    if audio_path:
        return _ai_fallback(audio_path, None, use_cache)
    
    if not text_prompt:
        return None
    
    # LEVEL 1: Quick Match
    quick_result = quick_match(text_prompt)
    if quick_result:
        return quick_result
    
    # LEVEL 2: Local Parser
    parser = SmartLocalParser()
    local_result = parser.parse(text_prompt)
    if local_result:
        if use_cache:
            command_cache.save_command(
                text_prompt, 
                local_result['actions'], 
                local_result['transcription']
            )
        return local_result
    
    # LEVEL 3: Cache
    if use_cache:
        cached = command_cache.find_similar_command(text_prompt, threshold=cache_threshold)
        if cached:
            return {
                'transcription': cached['transcription'] or text_prompt,
                'actions': cached['actions'],
                'from_cache': True,
                'source': 'cache üíæ',
                'similarity': cached['similarity'],
                'tokens_saved': 100
            }
    
    # LEVEL 4: AI Fallback
    return _ai_fallback(None, text_prompt, use_cache)

def _ai_fallback(audio_path: str = None, text_prompt: str = None, use_cache: bool = True) -> dict:
    """ÿßÿ≥ÿ™ÿØÿπÿßÿ° AI ŸÉŸÖŸÑÿßÿ∞ ÿ£ÿÆŸäÿ±."""
    model = genai.GenerativeModel('gemini-2.5-flash')
    prompt_content = [_get_system_prompt()]
    
    if audio_path:
        myfile = genai.upload_file(audio_path)
        prompt_content.append(myfile)
    elif text_prompt:
        prompt_content.append(text_prompt)
    else:
        return None
    
    try:
        response = model.generate_content(prompt_content)
        raw_text = response.text.replace('```json', '').replace('```', '').strip()
        data = json.loads(raw_text)
        
        validated = CommandResponse(**data)
        result = validated.model_dump()
        result['from_cache'] = False
        result['source'] = 'AI ü§ñ'
        
        if use_cache:
            transcription = result.get('transcription', text_prompt or '')
            command_cache.save_command(transcription, result['actions'], transcription)
        
        return result

    except Exception as e:
        st.error(f"‚ùå AI Error: {e}")
        return None

# ============================================
# SMART CONFIRMATION
# ============================================
def smart_confirmation(text: str) -> Optional[str]:
    """ŸÅŸáŸÖ ÿßŸÑÿ™ÿ£ŸÉŸäÿØ ŸÖÿ≠ŸÑŸäÿßŸã."""
    if not text:
        return None
    
    text_lower = text.lower().strip()
    
    yes_keywords = ['ŸÜÿπŸÖ', 'yes', 'ŸÜŸÅÿ∞', 'ok', 'ŸÖŸàÿßŸÅŸÇ', 'ÿ™ŸÖÿßŸÖ', 'ÿßŸá', 'ÿµÿ≠', 'ŸÖÿßÿ¥Ÿä']
    no_keywords = ['ŸÑÿß', 'no', 'ÿ•ŸÑÿ∫ÿßÿ°', 'cancel', 'stop', 'ŸÖÿ¥ ÿπÿßŸäÿ≤']
    edit_keywords = ['ÿπÿØŸÑ', 'edit', 'ÿ∫Ÿäÿ±', 'change', 'ÿ®ÿØŸÑ', 'ŸÖÿ¥ ŸÉÿØŸá']
    
    if any(word in text_lower for word in yes_keywords):
        return 'yes'
    if any(word in text_lower for word in no_keywords):
        return 'no'
    if any(word in text_lower for word in edit_keywords):
        return 'edit'
    
    return None

def parse_confirmation_command(audio_path: str = None, text: str = None) -> Optional[str]:
    if text:
        local_result = smart_confirmation(text)
        if local_result:
            return local_result
    
    if audio_path:
        try:
            model = genai.GenerativeModel('gemini-2.5-flash')
            res = model.generate_content([
                "Reply: yes/no/edit",
                genai.upload_file(audio_path)
            ])
            txt = res.text.lower()
            if 'yes' in txt:
                return 'yes'
            if 'no' in txt:
                return 'no'
            if 'edit' in txt:
                return 'edit'
        except:
            pass
    
    return None

def analyze_confirmation(audio_path: str) -> str:
    return parse_confirmation_command(audio_path=audio_path) or "no"

# ============================================
# STATISTICS
# ============================================
def get_token_savings_stats() -> dict:
    """ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿßŸÑÿ™ŸàŸÅŸäÿ±."""
    try:
        stats = command_cache.get_usage_stats()
        total_commands = stats['total_uses']
        cache_hits = total_commands - stats['unique']
        tokens_saved = cache_hits * 100
        cost_saved = (tokens_saved / 1_000_000) * 0.15
        
        return {
            'total_commands': total_commands,
            'unique_commands': stats['unique'],
            'cache_hits': cache_hits,
            'tokens_saved': tokens_saved,
            'money_saved_usd': cost_saved,
            'cache_hit_rate': (cache_hits / total_commands * 100) if total_commands > 0 else 0
        }
    except:
        return {
            'total_commands': 0,
            'unique_commands': 0,
            'cache_hits': 0,
            'tokens_saved': 0,
            'money_saved_usd': 0,
            'cache_hit_rate': 0
        }
