## المونتير الذكي (AI Voice Video Editor)

تطبيق مونتاج فيديو ذكي يعتمد على **الأوامر الصوتية/النصية** ويحوّلها إلى خطوات تحرير فيديو تُنفَّذ تلقائياً باستخدام Python و MoviePy و FFmpeg، مع واجهة تفاعلية عبر Streamlit.

## الفكرة

بدلاً من التعامل اليدوي مع الـ Timeline، يقوم المستخدم بإعطاء أمر مثل: “شيل أول 5 ثواني، وكتم الصوت، وخلي الفيديو أبيض وأسود”، ويقوم التطبيق بتحليل الأمر عبر نموذج ذكاء اصطناعي ثم تنفيذ التعديلات بالتسلسل وتصدير فيديو نهائي.

## المميزات الحالية (حسب التطبيق)

- **واجهة Streamlit** لرفع الفيديو، عرض الفيديو، وإظهار “شريط زمني مرئي” (Thumbnails).
- **أوامر صوتية**: تسجيل من المتصفح ثم إرسال ملف الصوت للتحليل.
- **أوامر كتابية**: إدخال نصي مباشر.
- **تحليل ذكي عبر Gemini**: النموذج `gemini-2.5-flash` يعيد **JSON Array** من الخطوات.
- **تنفيذ متسلسل**: تطبيق الخطوات على الفيديو خطوة بخطوة.
- **تصدير**: ترميز `libx264` للصورة و `aac` للصوت.
- **مجلد إخراج منظم**: `My_Produced_Videos/` مع اسم ملف يعتمد على الوقت.
- **Caching**: تقليل إعادة التحليل للأوامر المتكررة عبر `@st.cache_data(persist="disk")`.
- **FFmpeg مضمّن**: وجود `ffmpeg.exe/ffprobe.exe/ffplay.exe` داخل مجلد المشروع، والتطبيق يضيف مسار المشروع إلى `PATH`.
- **توافق Python 3.13 للصوت**: fallback إلى `audioop_lts` عند غياب `audioop`.

## الأوامر المدعومة حالياً

يعيد الذكاء الاصطناعي قائمة مهام بصيغة JSON Array. الصيغ المدعومة في `app.py`:

- **trim**: قص مقطع زمني
  - الحقول: `start` (ثوانٍ)، `end` (ثوانٍ)
- **mute**: كتم الصوت
- **speed**: تغيير السرعة
  - الحقل: `factor` (مثل 1.5 أو 2.0)
- **black_white**: فلتر أبيض وأسود

مثال:

```json
[
  { "action": "trim", "start": 0, "end": 5 },
  { "action": "mute" },
  { "action": "speed", "factor": 2.0 },
  { "action": "black_white" }
]
```

## التشغيل (Windows)

### المتطلبات

- Python (مفضل 3.10–3.12، ويدعم 3.13 مع `audioop_lts`)
- اتصال إنترنت + مفتاح Google Gemini API
- FFmpeg: موجود داخل المشروع بالفعل

### الإعداد

1. إنشاء بيئة افتراضية وتثبيت المتطلبات:

```bash
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

2. إنشاء ملف `.env` في جذر المشروع (لا تقم بمشاركته أو رفعه):

```env
GOOGLE_API_KEY=YOUR_KEY_HERE
```

### تشغيل واجهة Streamlit

```bash
streamlit run app.py
```

### تشغيل نسخة سطر الأوامر (اختياري)

يوجد سكربت بسيط في `main.py` للتجربة عبر أمر نصي على ملف `input.mp4`:

```bash
python main.py
```

## هيكل المشروع (مختصر)

- `app.py`: تطبيق Streamlit (رفع فيديو + Timeline + صوت/نص + تنفيذ + تصدير).
- `main.py`: تجربة CLI بسيطة.
- `style.css`: ستايل للـ Timeline وبعض تحسينات الواجهة.
- `ffmpeg.exe`, `ffprobe.exe`, `ffplay.exe`: أدوات FFmpeg محلياً.
- `PROJECT_SPEC.md`: وثيقة توصيف المشروع (هذه الوثيقة تفصيلية).

## ملاحظات وأمان

- **لا تضع مفتاح API داخل الكود**. استخدم `.env`.
- يُفضل عدم رفع ملفات فيديو حساسة إذا كنت ستعتمد على تحليل خارجي (بحسب طريقة الاستخدام وتكوين الـ API).

## خارطة طريق (الهدف النهائي)

- توسيع دعم الأوامر (دمج/تقسيم/ترجمة/ضبط صوت/إزالة ضجيج…).
- تحسين “لغة” JSON الناتجة والتحقق منها قبل التنفيذ.
- تحويل النموذج الأولي إلى **تطبيق سطح مكتب** (Desktop App) جاهز للمبدعين.
